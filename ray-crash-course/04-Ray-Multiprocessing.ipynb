{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray Crash Course - Python Multiprocessing with Ray\n",
    "\n",
    "Â© 2019-2020, Anyscale. All Rights Reserved\n",
    "\n",
    "![Anyscale Academy](../images/AnyscaleAcademy_Logo_clearbanner_141x100.png)\n",
    "\n",
    "This lesson explores how to replace two popular multiprocessing libraries with Ray replacements to break the one-machine boundary:\n",
    "\n",
    "* [`multiprocessing.Pool`](https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing.pool) for general management of process pools.\n",
    "* [`joblib`](https://joblib.readthedocs.io/en/latest/), the underpinnings of [scikit-learn](https://scikit-learn.org/stable/), which Ray can scale to a cluster.\n",
    "\n",
    "We also examine how Ray can work with Python's [`asyncio`](https://docs.python.org/3/library/asyncio.html).\n",
    "\n",
    "> **Tip:** For more about Ray, see [ray.io](https://ray.io) or the [Ray documentation](https://docs.ray.io/en/latest/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray, time, sys, os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Ray is already running.\n"
     ]
    }
   ],
   "source": [
    "!../tools/start-ray.sh --check --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.1.114',\n",
       " 'raylet_ip_address': '192.168.1.114',\n",
       " 'redis_address': '192.168.1.114:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2020-07-20_13-12-17_876312_3947/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-07-20_13-12-17_876312_3947/sockets/raylet',\n",
       " 'webui_url': 'localhost:8265',\n",
       " 'session_dir': '/tmp/ray/session_2020-07-20_13-12-17_876312_3947'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(address='auto', ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Ray Dashboard, if you are running this notebook on a local machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard URL: http://localhost:8265\n"
     ]
    }
   ],
   "source": [
    "print(f'Dashboard URL: http://{ray.get_webui_url()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop-in Replacements for Popular Single-node, Multiprocessing Libraries\n",
    "\n",
    "The Python community has three popular libraries for breaking out of Python's _global interpreter lock_ to enable better multiprocessing and concurrency. Ray now offers drop-in replacements for two of them, [`multiprocessing.Pool`](https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing.pool) and [`joblib`](https://joblib.readthedocs.io/en/latest/), and integration with the third, Python's [`asyncio`](https://docs.python.org/3/library/asyncio.html).\n",
    "\n",
    "This section explores the `multiprocessing.Pool` and `joblib` replacements.\n",
    "\n",
    "| Library | Library Docs | Ray Docs | Description |\n",
    "| :------ | :----------- | :------- | :---------- |\n",
    "| `multiprocessing.Pool` | [docs](https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing.pool) | [Ray](https://docs.ray.io/en/latest/multiprocessing.html) | Create a pool of processes for running work. The Ray replacement allows scaling to a cluster. |\n",
    "| `joblib` | [docs](https://joblib.readthedocs.io/en/latest/) | [Ray](https://docs.ray.io/en/latest/joblib.html) | Ray supports running distributed [scikit-learn](https://scikit-learn.org/stable/) programs by implementing a Ray backend for `joblib` using Ray Actors instead of local processes. This makes it easy to scale existing applications that use scikit-learn from a single node to a cluster. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocessing.Pool\n",
    "\n",
    "If your application already uses `multiprocessing.Pool`, then scaling beyond a single node just requires replacing your import statements from this:\n",
    "\n",
    "```python\n",
    "from multiprocessing.pool import Pool\n",
    "```\n",
    "\n",
    "To this:\n",
    "\n",
    "```python\n",
    "from ray.util.multiprocessing.pool import Pool\n",
    "```\n",
    "\n",
    "A local Ray cluster will be started the first time you create a Pool and your tasks will be distributed across it. See [Run on a Cluster](https://docs.ray.io/en/latest/multiprocessing.html#run-on-a-cluster) in the Ray documentation for details on how to use a multi-node Ray cluster instead.\n",
    "\n",
    "Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0|1|2|3|4|5|6|7|8|9|10|11|12|13|14|15|16|17|18|19|20|21|22|23|24|25|26|27|28|29|30|31|32|33|34|35|36|37|38|39|40|41|42|43|44|45|46|47|48|49|50|51|52|53|54|55|56|57|58|59|60|61|62|63|64|65|66|67|68|69|70|71|72|73|74|75|76|77|78|79|80|81|82|83|84|85|86|87|88|89|90|91|92|93|94|95|96|97|98|99|"
     ]
    }
   ],
   "source": [
    "from ray.util.multiprocessing import Pool\n",
    "\n",
    "def f(index):\n",
    "    return index\n",
    "\n",
    "def run_with_pool(n=100):\n",
    "    pool = Pool()\n",
    "    for result in pool.map(f, range(n)):\n",
    "        print(f'{result}|', end='')\n",
    "\n",
    "run_with_pool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used a function `run_with_pool()` to wrap a scope around the `pool` construction. That way, it goes out of scope when we're finished and Ray can reclaim the resources.\n",
    "\n",
    "The full `multiprocessing.Pool` API is supported. Please see Python's [multiprocessing documentation](https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing.pool) for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joblib\n",
    "\n",
    "Ray supports running distributed [scikit-learn](https://scikit-learn.org/) programs by implementing a Ray backend for [joblib](https://joblib.readthedocs.io/) using Ray Actors instead of local processes. This makes it easy to scale existing applications that use scikit-learn from a single node to a cluster.\n",
    "\n",
    "> **Note:** This API is new and may be revised in the future. Please [report any issues](https://github.com/ray-project/ray/issues) you encounter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, use `from ray.util.joblib import register_ray` and then run `register_ray()`. This will register Ray as a `joblib` backend for `scikit-learn` to use. Then run your original `scikit-learn` code inside `with joblib.parallel_backend('ray')`. This will start a local Ray cluster. \n",
    "\n",
    "See [Run on a Cluster](https://docs.ray.io/en/latest/joblib.html#run-on-a-cluster) in the Ray documentation for details on how to use a multi-node Ray cluster instead.\n",
    "\n",
    "Here is an example. First, we set up Ray with `joblib`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from ray.util.joblib import register_ray\n",
    "register_ray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use an example taken from the scikit-learn examples, [Restricted Boltzmann Machine features for digit classification](https://scikit-learn.org/stable/auto_examples/neural_networks/plot_rbm_logistic_classification.html#sphx-glr-auto-examples-neural-networks-plot-rbm-logistic-classification-py). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authors: Yann N. Dauphin, Vlad Niculae, Gabriel Synnaeve\n",
    "# License: BSD\n",
    "\n",
    "import numpy as np\n",
    "from scipy.ndimage import convolve\n",
    "from sklearn import linear_model, datasets, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# Setting up\n",
    "\n",
    "def nudge_dataset(X, Y):\n",
    "    \"\"\"\n",
    "    This produces a dataset 5 times bigger than the original one,\n",
    "    by moving the 8x8 images in X around by 1px to left, right, down, up\n",
    "    \"\"\"\n",
    "    direction_vectors = [\n",
    "        [[0, 1, 0],\n",
    "         [0, 0, 0],\n",
    "         [0, 0, 0]],\n",
    "\n",
    "        [[0, 0, 0],\n",
    "         [1, 0, 0],\n",
    "         [0, 0, 0]],\n",
    "\n",
    "        [[0, 0, 0],\n",
    "         [0, 0, 1],\n",
    "         [0, 0, 0]],\n",
    "\n",
    "        [[0, 0, 0],\n",
    "         [0, 0, 0],\n",
    "         [0, 1, 0]]]\n",
    "\n",
    "    def shift(x, w):\n",
    "        return convolve(x.reshape((8, 8)), mode='constant', weights=w).ravel()\n",
    "\n",
    "    X = np.concatenate([X] +\n",
    "                       [np.apply_along_axis(shift, 1, X, vector)\n",
    "                        for vector in direction_vectors])\n",
    "    Y = np.concatenate([Y for _ in range(5)], axis=0)\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "# Load Data\n",
    "X, y = datasets.load_digits(return_X_y=True)\n",
    "X = np.asarray(X, 'float32')\n",
    "X, Y = nudge_dataset(X, y)\n",
    "X = (X - np.min(X, 0)) / (np.max(X, 0) + 0.0001)  # 0-1 scaling\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Models we will use\n",
    "logistic = linear_model.LogisticRegression(solver='newton-cg', tol=1)\n",
    "rbm = BernoulliRBM(random_state=0, verbose=True)\n",
    "\n",
    "rbm_features_classifier = Pipeline(\n",
    "    steps=[('rbm', rbm), ('logistic', logistic)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# Training\n",
    "\n",
    "# Hyper-parameters. These were set by cross-validation,\n",
    "# using a GridSearchCV. Here we are not performing cross-validation to\n",
    "# save time.\n",
    "rbm.learning_rate = 0.06\n",
    "rbm.n_iter = 10\n",
    "# More components tend to give better prediction performance, but larger\n",
    "# fitting time\n",
    "rbm.n_components = 100\n",
    "logistic.C = 6000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we actually use the Ray backend for `joblib`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -25.39, time = 0.11s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -23.77, time = 0.16s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -22.94, time = 0.16s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -21.91, time = 0.15s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -21.69, time = 0.15s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -21.06, time = 0.15s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -20.89, time = 0.15s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -20.64, time = 0.15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-20 16:19:24,493\tWARNING pool.py:340 -- The 'context' argument is not supported using ray. Please refer to the documentation for how to control ray initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -20.36, time = 0.15s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -20.09, time = 0.15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-20 16:19:28,167\tWARNING pool.py:340 -- The 'context' argument is not supported using ray. Please refer to the documentation for how to control ray initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression using RBM features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       174\n",
      "           1       0.92      0.93      0.92       184\n",
      "           2       0.94      0.95      0.95       166\n",
      "           3       0.95      0.89      0.92       194\n",
      "           4       0.97      0.94      0.95       186\n",
      "           5       0.91      0.92      0.92       181\n",
      "           6       0.98      0.97      0.97       207\n",
      "           7       0.93      0.98      0.96       154\n",
      "           8       0.89      0.90      0.89       182\n",
      "           9       0.87      0.91      0.89       169\n",
      "\n",
      "    accuracy                           0.94      1797\n",
      "   macro avg       0.94      0.94      0.94      1797\n",
      "weighted avg       0.94      0.94      0.94      1797\n",
      "\n",
      "\n",
      "Logistic regression using raw pixel features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91       174\n",
      "           1       0.60      0.59      0.60       184\n",
      "           2       0.76      0.85      0.80       166\n",
      "           3       0.78      0.79      0.79       194\n",
      "           4       0.81      0.84      0.83       186\n",
      "           5       0.77      0.76      0.76       181\n",
      "           6       0.91      0.87      0.89       207\n",
      "           7       0.86      0.88      0.87       154\n",
      "           8       0.67      0.59      0.63       182\n",
      "           9       0.75      0.76      0.76       169\n",
      "\n",
      "    accuracy                           0.78      1797\n",
      "   macro avg       0.78      0.78      0.78      1797\n",
      "weighted avg       0.78      0.78      0.78      1797\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with joblib.parallel_backend('ray'):\n",
    "    # Training RBM-Logistic Pipeline\n",
    "    rbm_features_classifier.fit(X_train, Y_train)\n",
    "\n",
    "    # Training the Logistic regression classifier directly on the pixel\n",
    "    raw_pixel_classifier = clone(logistic)\n",
    "    raw_pixel_classifier.C = 100.\n",
    "    raw_pixel_classifier.fit(X_train, Y_train)\n",
    "\n",
    "    # #############################################################################\n",
    "    # Evaluation\n",
    "\n",
    "    Y_pred = rbm_features_classifier.predict(X_test)\n",
    "    print(\"Logistic regression using RBM features:\\n%s\\n\" % (\n",
    "        metrics.classification_report(Y_test, Y_pred)))\n",
    "\n",
    "    Y_pred = raw_pixel_classifier.predict(X_test)\n",
    "    print(\"Logistic regression using raw pixel features:\\n%s\\n\" % (\n",
    "        metrics.classification_report(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see warnings about the `The 'context' argument`, you can safely ignore them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Ray with asyncio\n",
    "\n",
    "Python's [`asyncio`](https://docs.python.org/3/library/asyncio.html) can be used with Ray actors and tasks.\n",
    "\n",
    "> **Note:** The Async API support is experimental and work is ongoing to improve it. Please [report any issues](https://github.com/ray-project/ray/issues) you encounter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actors\n",
    "Here is an actor example, adapted from the [Ray documentation](https://docs.ray.io/en/latest/async_api.html).\n",
    "\n",
    "Note the comment before `run_concurrent`. While normally actor methods are invoked synchronously, in this case there may be concurrent invocations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14981)\u001b[0m started 0\n",
      "\u001b[2m\u001b[36m(pid=14981)\u001b[0m started 10\n",
      "\u001b[2m\u001b[36m(pid=14981)\u001b[0m finished 0\n",
      "\u001b[2m\u001b[36m(pid=14981)\u001b[0m finished 10\n",
      "\u001b[2m\u001b[36m(pid=14981)\u001b[0m started 1\n",
      "\u001b[2m\u001b[36m(pid=14981)\u001b[0m started 11\n",
      "\u001b[2m\u001b[36m(pid=14981)\u001b[0m finished 1\n",
      "\u001b[2m\u001b[36m(pid=14981)\u001b[0m finished 11\n",
      "\u001b[2m\u001b[36m(pid=14981)\u001b[0m started 2\n",
      "\u001b[2m\u001b[36m(pid=14981)\u001b[0m started 12\n",
      "\u001b[2m\u001b[36m(pid=14981)\u001b[0m finished 2\n",
      "\u001b[2m\u001b[36m(pid=14981)\u001b[0m finished 12\n",
      "\u001b[2m\u001b[36m(pid=14981)\u001b[0m started 3\n",
      "\u001b[2m\u001b[36m(pid=14981)\u001b[0m started 13\n",
      "\u001b[2m\u001b[36m(pid=14981)\u001b[0m finished 3\n",
      "\u001b[2m\u001b[36m(pid=14981)\u001b[0m finished 13\n",
      "\u001b[2m\u001b[36m(pid=14981)\u001b[0m started 4\n",
      "\u001b[2m\u001b[36m(pid=14981)\u001b[0m started 14\n",
      "\u001b[2m\u001b[36m(pid=14981)\u001b[0m finished 4\n",
      "\u001b[2m\u001b[36m(pid=14981)\u001b[0m finished 14\n",
      "\u001b[2m\u001b[36m(pid=14981)\u001b[0m started 5\n",
      "\u001b[2m\u001b[36m(pid=14981)\u001b[0m started 15\n",
      "\u001b[2m\u001b[36m(pid=14981)\u001b[0m finished 5\n",
      "\u001b[2m\u001b[36m(pid=14981)\u001b[0m finished 15\n",
      "\u001b[2m\u001b[36m(pid=14981)\u001b[0m started 6\n",
      "\u001b[2m\u001b[36m(pid=14981)\u001b[0m started 16\n",
      "\u001b[2m\u001b[36m(pid=14981)\u001b[0m finished 6\n",
      "\u001b[2m\u001b[36m(pid=14981)\u001b[0m finished 16\n",
      "\u001b[2m\u001b[36m(pid=14981)\u001b[0m started 7\n",
      "\u001b[2m\u001b[36m(pid=14981)\u001b[0m started 17\n",
      "\u001b[2m\u001b[36m(pid=14981)\u001b[0m finished 7\n",
      "\u001b[2m\u001b[36m(pid=14981)\u001b[0m finished 17\n",
      "\u001b[2m\u001b[36m(pid=14981)\u001b[0m started 8\n",
      "\u001b[2m\u001b[36m(pid=14981)\u001b[0m started 18\n",
      "\u001b[2m\u001b[36m(pid=14981)\u001b[0m finished 8\n",
      "\u001b[2m\u001b[36m(pid=14981)\u001b[0m finished 18\n",
      "\u001b[2m\u001b[36m(pid=14981)\u001b[0m started 9\n",
      "\u001b[2m\u001b[36m(pid=14981)\u001b[0m started 19\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "@ray.remote\n",
    "class AsyncActor:\n",
    "    # Multiple invocations of this method can be running in\n",
    "    # the event loop at the same time.\n",
    "    async def run_concurrent(self, index):\n",
    "        print(f'started {index}')\n",
    "        await asyncio.sleep(0.2)   # Concurrent workload here\n",
    "        print(f'finished {index}')\n",
    "        return index\n",
    "\n",
    "actor = AsyncActor.remote()\n",
    "\n",
    "ids = []\n",
    "values = []\n",
    "for i in range(10):\n",
    "    # regular ray.get\n",
    "    ids.append(actor.run_concurrent.remote(i))\n",
    "\n",
    "    # async ray.get\n",
    "    values.append(await actor.run_concurrent.remote(10+i))\n",
    "print(ray.get(ids))\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that using `await` with a method invocation implicitly invokes `ray.get()` on the returned object id.\n",
    "\n",
    "Under the hood, Ray runs all of the methods inside a single python event loop.\n",
    "\n",
    "> **Note:** Running blocking `ray.get` and `ray.wait` inside async actor methods is not allowed, because `ray.get` will block the execution of the event loop.\n",
    "\n",
    "You can limit the number of concurrent task running at once using the `max_concurrency` flag. By default, 1000 tasks can be running concurrently. \n",
    "\n",
    "In the following cell, we set the `max_concurrency` to `3`, so the subsequent cell will run tasks three at a time. Since there are `12` total, we'll have four groups, each sleeping about `0.2` seconds, so it should take about `0.8` seconds to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor3 = AsyncActor.options(max_concurrency=3).remote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14981)\u001b[0m finished 9\n",
      "\u001b[2m\u001b[36m(pid=14981)\u001b[0m finished 19\n",
      "\u001b[2m\u001b[36m(pid=14987)\u001b[0m started 0\n",
      "\u001b[2m\u001b[36m(pid=14987)\u001b[0m started 1\n",
      "\u001b[2m\u001b[36m(pid=14987)\u001b[0m started 2\n",
      "\u001b[2m\u001b[36m(pid=14987)\u001b[0m finished 0\n",
      "\u001b[2m\u001b[36m(pid=14987)\u001b[0m started 3\n",
      "\u001b[2m\u001b[36m(pid=14987)\u001b[0m finished 1\n",
      "\u001b[2m\u001b[36m(pid=14987)\u001b[0m finished 2\n",
      "\u001b[2m\u001b[36m(pid=14987)\u001b[0m started 4\n",
      "\u001b[2m\u001b[36m(pid=14987)\u001b[0m started 5\n",
      "\u001b[2m\u001b[36m(pid=14987)\u001b[0m finished 3\n",
      "\u001b[2m\u001b[36m(pid=14987)\u001b[0m started 6\n",
      "\u001b[2m\u001b[36m(pid=14987)\u001b[0m finished 4\n",
      "\u001b[2m\u001b[36m(pid=14987)\u001b[0m finished 5\n",
      "\u001b[2m\u001b[36m(pid=14987)\u001b[0m started 7\n",
      "\u001b[2m\u001b[36m(pid=14987)\u001b[0m started 8\n",
      "\u001b[2m\u001b[36m(pid=14987)\u001b[0m finished 6\n",
      "\u001b[2m\u001b[36m(pid=14987)\u001b[0m started 9\n",
      "\u001b[2m\u001b[36m(pid=14987)\u001b[0m finished 7\n",
      "\u001b[2m\u001b[36m(pid=14987)\u001b[0m finished 8\n",
      "\u001b[2m\u001b[36m(pid=14987)\u001b[0m started 10\n",
      "\u001b[2m\u001b[36m(pid=14987)\u001b[0m started 11\n",
      "CPU times: user 54.8 ms, sys: 14.2 ms, total: 69 ms\n",
      "Wall time: 824 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time ray.get([actor3.run_concurrent.remote(i) for i in range(12)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the [03: Ray Internals](../advanced-ray/03-Ray-Internals.ipynb) lesson in the [Advanced Ray](../advanced-ray/00-Advanced-Ray-Overview.ipynb) tutorial for more details on _async actors_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Async Tasks\n",
    "\n",
    "For Ray tasks, the object ids returned by them can be converted to `async.Future` instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14987)\u001b[0m finished 9\n",
      "\u001b[2m\u001b[36m(pid=14987)\u001b[0m finished 10\n",
      "\u001b[2m\u001b[36m(pid=14987)\u001b[0m finished 11\n"
     ]
    }
   ],
   "source": [
    "@ray.remote\n",
    "def some_task():\n",
    "    return 1\n",
    "\n",
    "# The normal Ray way:\n",
    "id, _ = ray.wait([some_task.remote()])\n",
    "ray.get(id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `asyncio` alternative way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RayConnectionError",
     "evalue": "Ray has not been started yet. You can start Ray with 'ray.init()'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRayConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ee45c286a3a1>\u001b[0m in \u001b[0;36masync-def-wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/remote_function.py\u001b[0m in \u001b[0;36m_remote_proxy\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_remote_proxy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_remote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_remote_proxy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/remote_function.py\u001b[0m in \u001b[0;36m_remote\u001b[0;34m(self, args, kwargs, num_return_vals, is_direct_call, num_cpus, num_gpus, memory, object_store_memory, resources, max_retries)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;34m\"\"\"Submit the remote function for execution.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mworker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_worker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_connected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;31m# If this function was not exported in this session and job, we need to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/worker.py\u001b[0m in \u001b[0;36mcheck_connected\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \"\"\"\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnected\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             raise RayConnectionError(\"Ray has not been started yet. You can \"\n\u001b[0m\u001b[1;32m    209\u001b[0m                                      \"start Ray with 'ray.init()'.\")\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRayConnectionError\u001b[0m: Ray has not been started yet. You can start Ray with 'ray.init()'."
     ]
    }
   ],
   "source": [
    "await some_task.remote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({<Task finished coro=<_wrap_awaitable() done, defined at /home/paul/anaconda3/envs/anyscale-academy/lib/python3.7/asyncio/tasks.py:623> result=1>}, set())\n",
      "  <class 'set'> => {<Task finished coro=<_wrap_awaitable() done, defined at /home/paul/anaconda3/envs/anyscale-academy/lib/python3.7/asyncio/tasks.py:623> result=1>}\n",
      "  <class 'set'> => set()\n"
     ]
    }
   ],
   "source": [
    "future = await asyncio.wait([some_task.remote()])\n",
    "print(future)\n",
    "# A tuple is returned:\n",
    "for x in future:\n",
    "    print(f'  {type(x)} => {x}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the [asyncio docs](https://docs.python.org/3/library/asyncio-task.html) for more details on `asyncio` patterns, including timeouts and `asyncio.gather`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()  # \"Undo ray.init()\". Terminate all the processes started in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next lesson, [Ray Parallel Iterators](05-Ray-Parallel-Iterators.ipynb) introduces the _parallel iterator_ API for simple data ingestion and processing. It can be thought of as syntactic sugar around Ray actors and `ray.wait` loops."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "382.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
